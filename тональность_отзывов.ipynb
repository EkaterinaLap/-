{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFtw90j3nDbdP+OX5jCDhq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EkaterinaLap/-/blob/main/%D1%82%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%BE%D1%82%D0%B7%D1%8B%D0%B2%D0%BE%D0%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7t30S3-hnQz",
        "outputId": "f509add2-9982-45db-c089-ff32dbc0b998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              content       grade3  prediction\n",
            "0   'требую продолжения хочу ещё хочу 3 4 5 литера...  Нейтральная           0\n",
            "1   'часа красивых картинок дени вильнева часто уп...  Нейтральная           0\n",
            "2   'дюна картинок звука мало скажу сразу книгу чи...  Нейтральная           0\n",
            "3   'кропотливая работа матерей кончиках пальцев н...   Позитивная           1\n",
            "4   'рейтинг кинопоиске эээ это сравнению самобытн...   Негативная           2\n",
            "5   'пророк дюна часть вторая самых ожидаемых филь...   Позитивная           1\n",
            "6   'красивая обертка стоит признать люблю вильнёв...   Позитивная           1\n",
            "7   'желание отомстить приводит пола настоящей свя...  Нейтральная           0\n",
            "8   'красивый видеоряд сюжет вторая часть разорван...  Нейтральная           0\n",
            "9   'вышли кинотеатра фильм огонь часа выпали реал...  Нейтральная           0\n",
            "10  'дюна одна самых переоцененных книг средневеко...  Нейтральная           0\n",
            "11  'фильма читал трилогию пытался посмотреть филь...  Нейтральная           0\n",
            "12  'чушь подойдет качестве безмедикаментозного сн...   Позитивная           1\n",
            "13  'странное ощущение очень красиво совершенно це...   Негативная           2\n",
            "14  'нереально выбесила любовь протагониста вместо...   Позитивная           1\n",
            "15  'это самая сильная кино адаптация игры бесспор...   Позитивная           1\n"
          ]
        }
      ],
      "source": [
        "# Загружаем необходимые библиотеки и модули для анализа тональности текста\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, BertTokenizerFast\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import download\n",
        "# Загружаем набор стоп-слов\n",
        "download('stopwords')\n",
        "# Выполняем предварительную обработку текста для анализа\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^а-яА-ЯёЁa-zA-Z0-9\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "# Читаем отзывы из текстового файла\n",
        "def read_reviews_from_txt(filename):\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "        reviews = file.readlines()\n",
        "    return [review.strip() for review in reviews]\n",
        "# Загрузка модели и токенизатора для русского языка\n",
        "model_name = \"blanchefort/rubert-base-cased-sentiment\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "# Прогнозируем тональность текста\n",
        "def predict_sentiment(text):\n",
        "    text = preprocess_text(text)\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1).squeeze()\n",
        "    predicted_index = torch.argmax(probabilities).item()\n",
        "    return probabilities.tolist(), predicted_index\n",
        "# Читаем отзывы из текстового файла и сохраняем их в переменной\n",
        "reviews = read_reviews_from_txt(\"texts.txt\")\n",
        "# Создание пустого списка для результатов\n",
        "results = []\n",
        "for review in reviews:\n",
        "    probabilities, predicted_index = predict_sentiment(review)\n",
        "    results.append({\n",
        "        \"content\": review,\n",
        "        \"grade3\": {0: \"Нейтральная\", 1: \"Позитивная\", 2: \"Негативная\"}[predicted_index],\n",
        "        \"prediction\": predicted_index\n",
        "    })\n",
        "# Преобразование списка результатов в датафрейм\n",
        "df = pd.DataFrame(results)\n",
        "# Вывод датафрейма на экран\n",
        "print(df)"
      ]
    }
  ]
}